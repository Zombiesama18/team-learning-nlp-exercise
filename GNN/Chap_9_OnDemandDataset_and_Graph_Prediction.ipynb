{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from typing import Optional, Any, Callable, List, Tuple, Union\n",
    "from torch import Tensor\n",
    "from torch_geometric.typing import OptTensor\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "from ogb.utils import smiles2graph\n",
    "from ogb.utils.torch_util import replace_numpy_with_torchtensor\n",
    "from ogb.utils.url import download_url, extract_zip\n",
    "from rdkit import RDLogger\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.data.data import BaseData\n",
    "from ogb.lsc import PCQM4MEvaluator\n",
    "from gin_graph import GINGraphPooling\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 小图合并组成大图\n",
    "PyTorch Geometric中采用的将多个图封装成批的方式是，将小图作为连通组件（connected component）的形式合并，构建一个大图。于是小图的邻接矩阵存储在大图邻接矩阵的对角线上。\n",
    "#### 小图的属性增值与拼接\n",
    "将小图存储到大图中时需要对小图的属性做一些修改，一个最显著的例子就是要对节点序号增值。在最一般的形式中，`PyTorch Geometric`的`DataLoader`类会自动对`edge_index`张量增值，增加的值为当前被处理图的前面的图的累积节点数量。比方说，现在对第$k$个图的`edge_index`张量做增值，前面$k-1$个图的累积节点数量为$n$，那么对第$k$个图的`edge_index`张量的增值$n$。增值后，对所有图的`edge_index`张量（其形状为`[2, num_edges]`）在第二维中连接起来。\n",
    "然而，有一些特殊的场景中，基于需求我们希望能修改这一行为。`PyTorch Geometric`允许我们通过覆盖`torch_geometric.data.__inc__()`和`torch_geometric.data.__cat_dim__()`函数来实现我们希望的行为。\n",
    "\n",
    "案例：**图的匹配（Pairs of Graphs）**\n",
    "如果你想在一个`Data`对象中存储多个图，例如用于图匹配等应用，我们需要确保所有这些图的正确封装成批行为。例如，考虑将两个图，一个源图$G_s$和一个目标图$G_t$，存储在一个Data类中。在这种情况中，`edge_index_s`应该根据源图$G_s$的节点数做增值，即`x_s.size(0)`，而`edge_index_t`应该根据目标图$G_t$的节点数做增值，即`x_t.size(0)`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairData(Data):\n",
    "    def __init__(self, edge_index_s, x_s, edge_index_t, x_t, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.edge_index_s = edge_index_s\n",
    "        self.x_s = x_s\n",
    "        self.edge_index_t = edge_index_t\n",
    "        self.x_t = x_t\n",
    "    \n",
    "    def __inc__(self, key: str, value: Any, *args, **kwargs) -> Any:\n",
    "        if key == 'edge_index_s':\n",
    "            return self.x_s.size(0)\n",
    "        if key == 'edge_index_t':\n",
    "            return self.x_t.size(0)\n",
    "        return super().__inc__(key, value, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PairDataBatch(edge_index_s=[2, 8], x_s=[10, 16], edge_index_t=[2, 6], x_t=[8, 16])\n",
      "tensor([[0, 0, 0, 0, 5, 5, 5, 5],\n",
      "        [1, 2, 3, 4, 6, 7, 8, 9]])\n",
      "torch.Size([10, 16])\n",
      "tensor([[0, 0, 0, 4, 4, 4],\n",
      "        [1, 2, 3, 5, 6, 7]])\n"
     ]
    }
   ],
   "source": [
    "edge_index_s = torch.tensor([\n",
    "    [0, 0, 0, 0],\n",
    "    [1, 2, 3, 4],\n",
    "])\n",
    "x_s = torch.randn(5, 16)  # 5 nodes.\n",
    "edge_index_t = torch.tensor([\n",
    "    [0, 0, 0],\n",
    "    [1, 2, 3],\n",
    "])\n",
    "x_t = torch.randn(4, 16)  # 4 nodes.\n",
    "\n",
    "data = PairData(edge_index_s, x_s, edge_index_t, x_t)\n",
    "data_list = [data, data]\n",
    "loader = DataLoader(data_list, batch_size=2)\n",
    "batch = next(iter(loader))\n",
    "\n",
    "print(batch)\n",
    "\n",
    "print(batch.edge_index_s)\n",
    "print(batch.x_s.shape)\n",
    "print(batch.edge_index_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于`PyTorch Geometric`无法识别`PairData`对象中实际的图，所以`batch`属性（将大图每个节点映射到其各自对应的小图）没有正确工作。此时就需要`DataLoader`的`follow_batch`参数发挥作用。在这里，我们可以指定我们要为哪些属性维护批信息。\n",
    "`follow_batch=['x_s', 'x_t']`现在成功地为节点特征`x_s`和`x_t`分别创建了名为`x_s_batch`和`x_t_batch`的赋值向量。这些信息现在可以用来在一个单一的Batch对象中对多个图进行聚合操作，例如，全局池化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PairDataBatch(edge_index_s=[2, 8], x_s=[10, 16], x_s_batch=[10], x_s_ptr=[3], edge_index_t=[2, 6], x_t=[8, 16], x_t_batch=[8], x_t_ptr=[3])\n",
      "tensor([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])\n",
      "tensor([0, 0, 0, 0, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "loader = DataLoader(data_list, batch_size=2, follow_batch=['x_s', 'x_t'])\n",
    "batch = next(iter(loader))\n",
    "\n",
    "print(batch)\n",
    "print(batch.x_s_batch)\n",
    "print(batch.x_t_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 二部图\n",
    "二部图的邻接矩阵定义两种类型的节点之间的连接关系。一般来说，不同类型的节点数量不需要一致，于是二部图的邻接矩阵$A \\in {0,1}^{N \\times M}$可能为平方矩阵，即可能有$N \\neq M$。\n",
    "为了对二部图实现正确的封装成批，我们需要告诉`PyTorch Geometric`，它应该在`edge_index`中独立地为边的源节点和目标节点做增值操作。\n",
    "其中，`edge_index[0]`（边的源节点）根据`x_s.size(0)`做增值运算，而`edge_index[1]`（边的目标节点）根据`x_t.size(0)`做增值运算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BipartiteData(Data):\n",
    "    def __init__(self, edge_index, x_s, x_t):\n",
    "        super().__init__()\n",
    "        self.edge_index = edge_index\n",
    "        self.x_s = x_s\n",
    "        self.x_t = x_t\n",
    "    \n",
    "    def __inc__(self, key, value, *args):\n",
    "        if key == 'edge_index':\n",
    "            return torch.tensor([[self.x_s.size(0)], [self.x_t.size(0)]])\n",
    "        else:\n",
    "            return super().__inc__(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BipartiteDataBatch(edge_index=[2, 8], x_s=[4, 16], x_t=[6, 16], batch=[6], ptr=[3])\n",
      "tensor([[0, 0, 1, 1, 2, 2, 3, 3],\n",
      "        [0, 1, 1, 2, 3, 4, 4, 5]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gp.sc.cc.tohoku.ac.jp/duanct/miniconda3/envs/graphs/lib/python3.11/site-packages/torch_geometric/data/storage.py:327: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'x_s', 'edge_index', 'x_t'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "edge_index = torch.tensor([\n",
    "    [0, 0, 1, 1],\n",
    "    [0, 1, 1, 2],\n",
    "])\n",
    "x_s = torch.randn(2, 16)  # 2 nodes.\n",
    "x_t = torch.randn(3, 16)  # 3 nodes.\n",
    "\n",
    "data = BipartiteData(edge_index, x_s, x_t)\n",
    "data_list = [data, data]\n",
    "loader = DataLoader(data_list, batch_size=2)\n",
    "batch = next(iter(loader))\n",
    "\n",
    "print(batch)\n",
    "\n",
    "print(batch.edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用PCQM4M-LSC数据集来实践\n",
    "PCQM4M-LSC是一个分子图的量子特性回归数据集，它包含了3,803,453个图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "\n",
    "class MyPCQM4MDataset(Dataset):\n",
    "    def __init__(self, root: str | None = None, transform: Callable[..., Any] | None = None, pre_transform: Callable[..., Any] | None = None, pre_filter: Callable[..., Any] | None = None, log: bool = True):\n",
    "        self.url = 'https://dgl-data.s3-accelerate.amazonaws.com/dataset/OGB-LSC/pcqm4m_kddcup2021.zip'\n",
    "        super().__init__(root)\n",
    "        file_path = os.path.join(root, 'raw/data.csv.gz')\n",
    "        data_df = pd.read_csv(file_path)\n",
    "        self.smiles_list = data_df['smiles']\n",
    "        self.homolumogap_list = data_df['homolumogap']\n",
    "    \n",
    "    @property\n",
    "    def raw_file_names(self) -> str | List[str] | Tuple:\n",
    "        return 'data.csv.gz'\n",
    "    \n",
    "    def download(self):\n",
    "        path = download_url(self.url, self.root)\n",
    "        extract_zip(path, self.root)\n",
    "        os.unlink(path)\n",
    "        shutil.move(os.path.join(self.root, 'pcqm4m_kddcup2021/raw/data.csv.gz'), os.path.join(self.root, 'raw/data.csv.gz'))\n",
    "    \n",
    "    def len(self) -> int:\n",
    "        return len(self.smiles_list)\n",
    "    \n",
    "    def get(self, idx: int) -> BaseData:\n",
    "        smiles, homolumogap = self.smiles_list[idx], self.homolumogap_list[idx]\n",
    "        graph = smiles2graph(smiles)\n",
    "        assert(len(graph['edge_feat']) == graph['edge_index'].shape[1])\n",
    "        assert(len(graph['node_feat']) == graph['num_nodes'])\n",
    "        \n",
    "        x = torch.from_numpy(graph['node_feat']).to(torch.int64)\n",
    "        edge_index = torch.from_numpy(graph['edge_index']).to(torch.int64)\n",
    "        edge_attr = torch.from_numpy(graph['edge_feat']).to(torch.int64)\n",
    "        y = torch.Tensor([homolumogap])\n",
    "        num_nodes = int(graph['num_nodes'])\n",
    "        data = Data(x, edge_index, edge_attr, y, num_nodes=num_nodes)\n",
    "        return data\n",
    "\n",
    "    def get_idx_split(self):\n",
    "        split_dict = replace_numpy_with_torchtensor(torch.load(os.path.join(self.root, 'pcqm4m_kddcup2021/split_dict.pt')))\n",
    "        return split_dict\n",
    "    \n",
    "    \n",
    "def prepartion(task_name, device):\n",
    "    save_dir = os.path.join('saves', task_name)\n",
    "    if os.path.exists(save_dir):\n",
    "        for idx in range(1000):\n",
    "            if not os.path.exists(save_dir + '=' + str(idx)):\n",
    "                save_dir = save_dir + '=' + str(idx)\n",
    "                break\n",
    "\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    device = torch.device(\"cuda:\" + str(device)) if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    output_file = open(os.path.join(save_dir, 'output'), 'a')\n",
    "    return save_dir, device, output_file\n",
    "\n",
    "\n",
    "def train(model, device, loader, optimizer, criterion_fn):\n",
    "    model.train()\n",
    "    loss_accum = 0\n",
    "\n",
    "    for step, batch in enumerate(tqdm(loader)):\n",
    "        batch = batch.to(device)\n",
    "        pred = model(batch).view(-1,)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion_fn(pred, batch.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_accum += loss.detach().cpu().item()\n",
    "\n",
    "    return loss_accum / (step + 1)\n",
    "\n",
    "\n",
    "def eval(model, device, loader, evaluator):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _, batch in enumerate(tqdm(loader)):\n",
    "            batch = batch.to(device)\n",
    "            pred = model(batch).view(-1,)\n",
    "            y_true.append(batch.y.view(pred.shape).detach().cpu())\n",
    "            y_pred.append(pred.detach().cpu())\n",
    "\n",
    "    y_true = torch.cat(y_true, dim=0)\n",
    "    y_pred = torch.cat(y_pred, dim=0)\n",
    "    input_dict = {\"y_true\": y_true, \"y_pred\": y_pred}\n",
    "    return evaluator.eval(input_dict)[\"mae\"]\n",
    "\n",
    "\n",
    "def test(model, device, loader):\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _, batch in enumerate(loader):\n",
    "            batch = batch.to(device)\n",
    "            pred = model(batch).view(-1,)\n",
    "            y_pred.append(pred.detach().cpu())\n",
    "\n",
    "    y_pred = torch.cat(y_pred, dim=0)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = 'GINGraphPooling'\n",
    "num_layers = 5\n",
    "graph_pooling = 'sum'\n",
    "emb_dim = 256\n",
    "drop_ratio = 0.\n",
    "save_test = True\n",
    "batch_size = 1024\n",
    "epochs = 100\n",
    "weight_decay = 5e-5\n",
    "early_stop = 10\n",
    "dataset_root = '../datasets/PCQM4M'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir, device, output_file = prepartion(task_name, 0)\n",
    "nn_params = {\n",
    "    'num_layers': num_layers,\n",
    "    'emb_dim': emb_dim,\n",
    "    'drop_ratio': drop_ratio,\n",
    "    'graph_pooling': graph_pooling\n",
    "}\n",
    "dataset = MyPCQM4MDataset(dataset_root)\n",
    "split_idx = dataset.get_idx_split()\n",
    "train_data = dataset[split_idx['train']]\n",
    "valid_data = dataset[split_idx['valid']]\n",
    "test_data = dataset[split_idx['test']]\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_data, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2974/2974 [16:11<00:00,  3.06it/s]\n",
      "100%|██████████| 372/372 [01:51<00:00,  3.35it/s]\n",
      "100%|██████████| 2974/2974 [16:04<00:00,  3.08it/s]\n",
      "100%|██████████| 372/372 [01:51<00:00,  3.35it/s]\n",
      "100%|██████████| 2974/2974 [16:02<00:00,  3.09it/s]\n",
      "100%|██████████| 372/372 [01:50<00:00,  3.37it/s]\n",
      "100%|██████████| 2974/2974 [16:03<00:00,  3.09it/s]\n",
      "100%|██████████| 372/372 [01:50<00:00,  3.37it/s]\n",
      "100%|██████████| 2974/2974 [15:56<00:00,  3.11it/s]\n",
      "100%|██████████| 372/372 [01:50<00:00,  3.38it/s]\n",
      "100%|██████████| 2974/2974 [16:02<00:00,  3.09it/s]\n",
      "100%|██████████| 372/372 [01:50<00:00,  3.38it/s]\n",
      "100%|██████████| 2974/2974 [15:59<00:00,  3.10it/s]\n",
      "100%|██████████| 372/372 [01:49<00:00,  3.39it/s]\n",
      "100%|██████████| 2974/2974 [16:00<00:00,  3.10it/s]\n",
      "100%|██████████| 372/372 [01:49<00:00,  3.39it/s]\n",
      "100%|██████████| 2974/2974 [15:59<00:00,  3.10it/s]\n",
      "100%|██████████| 372/372 [01:50<00:00,  3.38it/s]\n",
      "100%|██████████| 2974/2974 [15:58<00:00,  3.10it/s]\n",
      "100%|██████████| 372/372 [01:49<00:00,  3.39it/s]\n",
      "100%|██████████| 2974/2974 [16:00<00:00,  3.10it/s]\n",
      "100%|██████████| 372/372 [01:50<00:00,  3.37it/s]\n",
      "100%|██████████| 2974/2974 [16:00<00:00,  3.10it/s]\n",
      "100%|██████████| 372/372 [01:50<00:00,  3.37it/s]\n",
      "100%|██████████| 2974/2974 [16:03<00:00,  3.09it/s]\n",
      "100%|██████████| 372/372 [01:50<00:00,  3.36it/s]\n",
      "100%|██████████| 2974/2974 [16:05<00:00,  3.08it/s]\n",
      "100%|██████████| 372/372 [01:50<00:00,  3.36it/s]\n",
      "100%|██████████| 2974/2974 [16:02<00:00,  3.09it/s]\n",
      "100%|██████████| 372/372 [01:50<00:00,  3.38it/s]\n",
      "100%|██████████| 2974/2974 [16:06<00:00,  3.08it/s]\n",
      "100%|██████████| 372/372 [01:50<00:00,  3.37it/s]\n",
      "100%|██████████| 2974/2974 [15:58<00:00,  3.10it/s]\n",
      "100%|██████████| 372/372 [01:50<00:00,  3.37it/s]\n",
      "100%|██████████| 2974/2974 [16:02<00:00,  3.09it/s]\n",
      "100%|██████████| 372/372 [01:50<00:00,  3.36it/s]\n",
      "100%|██████████| 2974/2974 [16:02<00:00,  3.09it/s]\n",
      "100%|██████████| 372/372 [01:50<00:00,  3.36it/s]\n",
      "100%|██████████| 2974/2974 [16:01<00:00,  3.09it/s]\n",
      "100%|██████████| 372/372 [01:50<00:00,  3.37it/s]\n",
      "100%|██████████| 2974/2974 [16:02<00:00,  3.09it/s]\n",
      "100%|██████████| 372/372 [01:50<00:00,  3.37it/s]\n",
      "100%|██████████| 2974/2974 [16:04<00:00,  3.08it/s]\n",
      "100%|██████████| 372/372 [01:50<00:00,  3.37it/s]\n",
      "100%|██████████| 2974/2974 [16:05<00:00,  3.08it/s]\n",
      "100%|██████████| 372/372 [01:50<00:00,  3.37it/s]\n",
      "100%|██████████| 2974/2974 [16:01<00:00,  3.09it/s]\n",
      "100%|██████████| 372/372 [01:50<00:00,  3.37it/s]\n",
      "100%|██████████| 2974/2974 [16:04<00:00,  3.08it/s]\n",
      "100%|██████████| 372/372 [01:50<00:00,  3.36it/s]\n",
      "100%|██████████| 2974/2974 [16:01<00:00,  3.09it/s]\n",
      "100%|██████████| 372/372 [01:50<00:00,  3.36it/s]\n",
      "100%|██████████| 2974/2974 [16:05<00:00,  3.08it/s]\n",
      "100%|██████████| 372/372 [01:50<00:00,  3.35it/s]\n",
      "100%|██████████| 2974/2974 [16:03<00:00,  3.09it/s]\n",
      "100%|██████████| 372/372 [01:50<00:00,  3.36it/s]\n",
      "100%|██████████| 2974/2974 [16:03<00:00,  3.09it/s]\n",
      "100%|██████████| 372/372 [01:50<00:00,  3.37it/s]\n",
      "100%|██████████| 2974/2974 [16:01<00:00,  3.09it/s]\n",
      "100%|██████████| 372/372 [01:50<00:00,  3.38it/s]\n",
      "100%|██████████| 2974/2974 [16:00<00:00,  3.10it/s]\n",
      "100%|██████████| 372/372 [01:50<00:00,  3.36it/s]\n",
      "100%|██████████| 2974/2974 [16:00<00:00,  3.10it/s]\n",
      "100%|██████████| 372/372 [01:50<00:00,  3.36it/s]\n",
      "100%|██████████| 2974/2974 [16:02<00:00,  3.09it/s]\n",
      "100%|██████████| 372/372 [01:50<00:00,  3.38it/s]\n",
      "100%|██████████| 2974/2974 [16:01<00:00,  3.09it/s]\n",
      "100%|██████████| 372/372 [01:50<00:00,  3.38it/s]\n",
      "100%|██████████| 2974/2974 [16:02<00:00,  3.09it/s]\n",
      "100%|██████████| 372/372 [01:50<00:00,  3.36it/s]\n",
      "100%|██████████| 2974/2974 [16:01<00:00,  3.09it/s]\n",
      "100%|██████████| 372/372 [01:50<00:00,  3.38it/s]\n",
      "100%|██████████| 2974/2974 [15:59<00:00,  3.10it/s]\n",
      "100%|██████████| 372/372 [01:50<00:00,  3.37it/s]\n",
      "100%|██████████| 2974/2974 [16:02<00:00,  3.09it/s]\n",
      "100%|██████████| 372/372 [01:50<00:00,  3.36it/s]\n",
      "100%|██████████| 2974/2974 [16:01<00:00,  3.09it/s]\n",
      "100%|██████████| 372/372 [01:50<00:00,  3.37it/s]\n",
      "100%|██████████| 2974/2974 [16:00<00:00,  3.09it/s]\n",
      "100%|██████████| 372/372 [01:50<00:00,  3.36it/s]\n",
      "100%|██████████| 2974/2974 [16:08<00:00,  3.07it/s]\n",
      "100%|██████████| 372/372 [01:51<00:00,  3.35it/s]\n",
      "100%|██████████| 2974/2974 [16:07<00:00,  3.08it/s]\n",
      "100%|██████████| 372/372 [01:51<00:00,  3.35it/s]\n",
      "100%|██████████| 2974/2974 [16:04<00:00,  3.08it/s]\n",
      "100%|██████████| 372/372 [01:50<00:00,  3.38it/s]\n",
      "100%|██████████| 2974/2974 [16:05<00:00,  3.08it/s]\n",
      "100%|██████████| 372/372 [01:50<00:00,  3.36it/s]\n",
      "100%|██████████| 2974/2974 [16:09<00:00,  3.07it/s]\n",
      "100%|██████████| 372/372 [01:50<00:00,  3.36it/s]\n",
      "100%|██████████| 2974/2974 [16:09<00:00,  3.07it/s]\n",
      "100%|██████████| 372/372 [01:50<00:00,  3.37it/s]\n",
      "100%|██████████| 2974/2974 [16:11<00:00,  3.06it/s]\n",
      "100%|██████████| 372/372 [01:50<00:00,  3.35it/s]\n",
      "100%|██████████| 2974/2974 [16:08<00:00,  3.07it/s]\n",
      "100%|██████████| 372/372 [01:51<00:00,  3.35it/s]\n",
      "100%|██████████| 2974/2974 [16:08<00:00,  3.07it/s]\n",
      "100%|██████████| 372/372 [01:50<00:00,  3.36it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "evaluator = PCQM4MEvaluator()\n",
    "criterion_fn = torch.nn.MSELoss()\n",
    "model = GINGraphPooling(**nn_params).to(device)\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'#Params: {num_params}', file=output_file, flush=True)\n",
    "print(model, file=output_file, flush=True)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.25)\n",
    "\n",
    "writer = SummaryWriter(save_dir)\n",
    "not_improved = 0\n",
    "best_valid_mae = 9999\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    print(f'======Epch {epoch}======', file=output_file, flush=True)\n",
    "    print('Training....', file=output_file, flush=True)\n",
    "    train_mae = train(model, device, train_loader, optimizer, criterion_fn)\n",
    "    print('Evaluating....', file=output_file, flush=True)\n",
    "    valid_mae = eval(model, device, valid_loader, evaluator)\n",
    "    print(f'Train {train_mae}, Validation {valid_mae}', file=output_file, flush=True)\n",
    "    writer.add_scalar('valid/mae', valid_mae, epoch)\n",
    "    writer.add_scalar('train/mae', train_mae, epoch)\n",
    "    if valid_mae < best_valid_mae:\n",
    "        best_valid_mae = valid_mae\n",
    "        if save_test:\n",
    "            print('Saving checkpoint....', file=output_file, flush=True)\n",
    "            checkpoint = {\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler.state_dict': scheduler.state_dict(),\n",
    "                'best_val_mae': best_valid_mae,\n",
    "                'num_params': num_params\n",
    "                }\n",
    "            torch.save(checkpoint, os.path.join(save_dir, 'checkpoint.pt'))\n",
    "            print('Predicting on test data....', file=output_file, flush=True)\n",
    "            y_pred = test(model, device, test_loader)\n",
    "            print('Saving test submission file....', file=output_file, flush=True)\n",
    "            evaluator.save_test_submission({'y_pred': y_pred}, save_dir)\n",
    "        \n",
    "        not_improved = 0\n",
    "    else:\n",
    "        not_improved += 1\n",
    "        if not_improved == early_stop:\n",
    "            print(f'Have not improved for {not_improved} epochs.', file=output_file, flush=True)\n",
    "            break\n",
    "    scheduler.step()\n",
    "\n",
    "writer.close()\n",
    "output_file.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
